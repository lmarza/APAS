{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiments ECAI24 on the no2 dataset\n",
    "\n",
    "7 input features, all continuous. No known distribution shifts in this dataset, so it is used to mimic the daily model updates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# sci-kit learn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from util_scripts.convert import extract_sklearn_params, custom_nn_model\n",
    "\n",
    "from joblib import dump, load\n",
    "import gurobipy\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 150\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from util_scripts.preprocessor import Preprocessor, min_max_scale\n",
    "from util_scripts.utilexp import *\n",
    "from interval import *\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "CYAN_COL = '\\033[96m'\n",
    "BLUE_COL = '\\033[94m'\n",
    "RED_COL = '\\033[91m'\n",
    "GREEN_COL = '\\033[92m'\n",
    "YELLOW_COL = '\\033[93m'\n",
    "RESET_COL = '\\033[0m'\n",
    "BOLD = '\\033[1m'\n",
    "UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no2_concentration</th>\n",
       "      <th>cars_per_hour</th>\n",
       "      <th>temperature_at_2m</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>temperature_diff_2m_25m</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>binaryClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482404</td>\n",
       "      <td>0.844284</td>\n",
       "      <td>0.700252</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.546392</td>\n",
       "      <td>0.202801</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.362831</td>\n",
       "      <td>0.846118</td>\n",
       "      <td>0.629723</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.525773</td>\n",
       "      <td>0.151261</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.404232</td>\n",
       "      <td>0.162280</td>\n",
       "      <td>0.375315</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.546392</td>\n",
       "      <td>0.782353</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.611930</td>\n",
       "      <td>0.669122</td>\n",
       "      <td>0.287154</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.680412</td>\n",
       "      <td>0.201681</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.603835</td>\n",
       "      <td>0.803270</td>\n",
       "      <td>0.435768</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.546392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.596692</td>\n",
       "      <td>0.842110</td>\n",
       "      <td>0.556675</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.453608</td>\n",
       "      <td>0.212885</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.332732</td>\n",
       "      <td>0.569073</td>\n",
       "      <td>0.707809</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>0.582633</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.570573</td>\n",
       "      <td>0.860087</td>\n",
       "      <td>0.599496</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>0.593838</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.334757</td>\n",
       "      <td>0.393904</td>\n",
       "      <td>0.680101</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.288660</td>\n",
       "      <td>0.298319</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.543129</td>\n",
       "      <td>0.955865</td>\n",
       "      <td>0.586902</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.597938</td>\n",
       "      <td>0.574230</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     no2_concentration  cars_per_hour  temperature_at_2m  wind_speed  \\\n",
       "0             0.482404       0.844284           0.700252    0.468750   \n",
       "1             0.362831       0.846118           0.629723    0.333333   \n",
       "2             0.404232       0.162280           0.375315    0.062500   \n",
       "3             0.611930       0.669122           0.287154    0.145833   \n",
       "4             0.603835       0.803270           0.435768    0.239583   \n",
       "..                 ...            ...                ...         ...   \n",
       "495           0.596692       0.842110           0.556675    0.489583   \n",
       "496           0.332732       0.569073           0.707809    0.645833   \n",
       "497           0.570573       0.860087           0.599496    0.447917   \n",
       "498           0.334757       0.393904           0.680101    0.020833   \n",
       "499           0.543129       0.955865           0.586902    0.583333   \n",
       "\n",
       "     temperature_diff_2m_25m  wind_direction  hour_of_day  binaryClass  \n",
       "0                   0.546392        0.202801     0.826087            0  \n",
       "1                   0.525773        0.151261     0.565217            1  \n",
       "2                   0.546392        0.782353     0.130435            0  \n",
       "3                   0.680412        0.201681     0.956522            1  \n",
       "4                   0.546392        0.176471     0.434783            1  \n",
       "..                       ...             ...          ...          ...  \n",
       "495                 0.453608        0.212885     0.434783            1  \n",
       "496                 0.474227        0.582633     0.391304            1  \n",
       "497                 0.474227        0.593838     0.565217            1  \n",
       "498                 0.288660        0.298319     0.260870            0  \n",
       "499                 0.597938        0.574230     0.695652            1  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./datasets/no2/no2.csv\")\n",
    "df = df.dropna()\n",
    "df = df.replace(to_replace={'N': 0, 'P': 1})\n",
    "ordinal_features = {}\n",
    "discrete_features = {}\n",
    "continuous_features = list(df.columns)[:-1]\n",
    "CLASS = \"binaryClass\"\n",
    "\n",
    "# min max scale\n",
    "min_vals = np.min(df[continuous_features], axis=0)\n",
    "max_vals = np.max(df[continuous_features], axis=0)\n",
    "df_mm = min_max_scale(df, continuous_features, min_vals, max_vals)\n",
    "columns = list(df_mm.columns)\n",
    "display(df_mm)\n",
    "# get X, y\n",
    "X, y = df_mm.drop(columns=['binaryClass']), pd.DataFrame(df_mm['binaryClass'])\n",
    "\n",
    "SPLIT = .2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=SPLIT, shuffle=True,\n",
    "                                                    random_state=0)\n",
    "feat_var_map = {}\n",
    "for i in range(len(X.columns)):\n",
    "    feat_var_map[i] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "idx_1 = np.sort(np.random.choice(range(500), 250))\n",
    "idx_2 = np.array([i for i in range(500) if i not in idx_1])\n",
    "\n",
    "X1 = pd.DataFrame(data=X.values[idx_1], columns=X.columns)\n",
    "y1 = pd.DataFrame(data=y.values[idx_1], columns=y.columns)\n",
    "X2 = pd.DataFrame(data=X.values[idx_2], columns=X.columns)\n",
    "y2 = pd.DataFrame(data=y.values[idx_2], columns=y.columns)\n",
    "\n",
    "SPLIT = .2\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, stratify=y1, test_size=SPLIT, shuffle=True,\n",
    "                                                        random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train models and Observe model shifts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Randomdised search + 5-fold cross validation (default)\n",
    "nn = MLPClassifier(learning_rate='adaptive', random_state=0)\n",
    "\n",
    "# parameters\n",
    "max_iter_vals = [int(i) for i in np.linspace(1000, 10000, 10)]\n",
    "hidden_layer_sizes_vals = [(i) for i in range(5, 25)]\n",
    "batch_size_vals = [8, 16, 32, 64]\n",
    "learning_rate_init_vals = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05]\n",
    "\n",
    "#distributions = dict(max_iter=max_iter_vals, hidden_layer_sizes=hidden_layer_sizes_vals)\n",
    "distributions = dict(hidden_layer_sizes=hidden_layer_sizes_vals,\n",
    "                     batch_size=batch_size_vals,\n",
    "                     learning_rate_init=learning_rate_init_vals,\n",
    "                     max_iter=max_iter_vals, )\n",
    "\n",
    "#nns = RandomizedSearchCV(nn, distributions, scoring='f1_macro')\n",
    "#nns = RandomizedSearchCV(nn, distributions, scoring='accuracy')\n",
    "#search = nns.fit(X, y)\n",
    "#print(search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61 test_accuracy with a std of 0.04\n",
      "0.62 test_precision_macro with a std of 0.05\n",
      "0.61 test_recall_macro with a std of 0.04\n",
      "0.61 test_f1_macro with a std of 0.04\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " bad credit (0)      0.700     0.538     0.609        26\n",
      "good credit (1)      0.600     0.750     0.667        24\n",
      "\n",
      "       accuracy                          0.640        50\n",
      "      macro avg      0.650     0.644     0.638        50\n",
      "   weighted avg      0.652     0.640     0.637        50\n",
      "\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " bad credit (0)      0.785     0.716     0.749       102\n",
      "good credit (1)      0.729     0.796     0.761        98\n",
      "\n",
      "       accuracy                          0.755       200\n",
      "      macro avg      0.757     0.756     0.755       200\n",
      "   weighted avg      0.758     0.755     0.755       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(learning_rate='adaptive', hidden_layer_sizes=16, learning_rate_init=0.005, batch_size=8,\n",
    "                    max_iter=2000, random_state=0)\n",
    "\n",
    "# 5-fold cross validation\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n",
    "for name in list(scores.keys()):\n",
    "    if name == 'fit_time' or name == 'score_time':\n",
    "        continue\n",
    "    print(\"%0.2f %s with a std of %0.2f\" % (scores[name].mean(), name, scores[name].std()))\n",
    "\n",
    "clf = MLPClassifier(learning_rate='adaptive', hidden_layer_sizes=16, learning_rate_init=0.005, batch_size=8,\n",
    "                    max_iter=2000, random_state=0)\n",
    "\n",
    "clf.fit(X1_train, y1_train)\n",
    "resres = clf.predict(X1_test.values)\n",
    "print('\\n', classification_report(y1_test, resres, target_names=[f'bad credit (0)', f'good credit (1)'], digits=3))\n",
    "resres = clf.predict(X1_train.values)\n",
    "print('\\n', classification_report(y1_train, resres, target_names=[f'bad credit (0)', f'good credit (1)'], digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no2.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(clf, 'no2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiments: computing counterfactuals\n",
    "\n",
    "#### Procedures\n",
    "\n",
    "These procedures are covered by UtilExp class\n",
    "\n",
    "1. Train M on D1\n",
    "2. Get delta-min, build M+ and M-: incrementally train M 5 times, using different 10% of D2 each time, then get the maximum inf-distance between the incremented models and M. Construct M+ and M- using delta-min\n",
    "3. Get M2: incrementally train M on D2\n",
    "4. Select test instances: randomly select 50 D1 instances to explain, clf(x)=0, desired class=1\n",
    "5. Report metrics using each baseline\n",
    "\n",
    "#### Metrics\n",
    "- Proximity: normalised L1: \"Scaling Guarantees for Nearest CEs\" page 7\n",
    "- Sparsity: L0\n",
    "- Validity-delta: percentage of test instances that 1) have counterfactuals valid on m1, 2) counterfactuals valid on M+ and M- under delta_min\n",
    "- Validity-m2: percentage of test instances that 1) have counterfactual(s), 2) these counterfactual(s) are all valid on both m1 and m2\n",
    "- LOF: average LOF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Set parameter FeasibilityTol to value 0.001\n",
      "Set parameter OptimalityTol to value 0.001\n",
      "Set parameter IntFeasTol to value 0.001\n"
     ]
    }
   ],
   "source": [
    "clf = load(\"no2.joblib\")\n",
    "gurobipy.setParam(\"FeasibilityTol\", 1e-03)\n",
    "gurobipy.setParam(\"OptimalityTol\", 1e-03)\n",
    "gurobipy.setParam(\"IntFeasTol\", 1e-03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11449453866860582\n",
      "0.020924421229148754\n"
     ]
    }
   ],
   "source": [
    "util_exp = UtilExp(clf, X1, y1, X2, y2, columns, ordinal_features, discrete_features, continuous_features, feat_var_map, num_test_instances=200, gap=0.15)\n",
    "print(util_exp.delta_max)\n",
    "print(util_exp.delta_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model trained on the whole dataset\n",
    "m2 = copy.deepcopy(clf)\n",
    "m2.partial_fit(X2, y2)\n",
    "util_exp.Mmax = m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of sound model changes: 0.4424778761061947\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# pre-verification on the points soundness \n",
    "valids = util_exp.verify_soundness()\n",
    "print(len(valids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of sound model changes: 0.4424778761061947\n",
      "test instances updated to sound (x, Delta) pairs, length: 50\n"
     ]
    }
   ],
   "source": [
    "valids = util_exp.verify_soundness(update_test_instances=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the $\\delta$ difference between m1 and m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The maximum distance between weights is: 0.07160799\n"
     ]
    }
   ],
   "source": [
    "input_size, n_layers, output_size, output_act, h_act, optimizer, params = extract_sklearn_params(clf)\n",
    "tf_model = custom_nn_model(input_size, n_layers, params, output_size, h_act, output_act, optimizer)\n",
    "     \n",
    "# Set model weights\n",
    "for k, v in params.items():\n",
    "\ttf_model.layers[k].set_weights(v)\n",
    "        \n",
    "tf_model.save('./models/no2.h5', save_format='h5')   \n",
    "\n",
    "input_size, n_layers, output_size, output_act, h_act, optimizer, params = extract_sklearn_params(m2)\n",
    "tf_model = custom_nn_model(input_size, n_layers, params, output_size, h_act, output_act, optimizer)\n",
    "     \n",
    "# Set model weights\n",
    "for k, v in params.items():\n",
    "\ttf_model.layers[k].set_weights(v)\n",
    "\t\n",
    "tf_model.save('./models/no2_retrained.h5', save_format='h5')  \n",
    "\n",
    "original_model = tf.keras.models.load_model('./models/no2.h5', compile=False)\n",
    "old_weights = {}\n",
    "for l in range(1,len(original_model.layers)):\n",
    "\told_weights[l] = original_model.layers[l].get_weights()\n",
    "\n",
    "\n",
    "model_retrained = tf.keras.models.load_model('./models/no2_retrained.h5', compile=False)\n",
    "retrained_weights = {}\n",
    "for l in range(1,len(model_retrained.layers)):\n",
    "\tretrained_weights[l] = model_retrained.layers[l].get_weights()\n",
    "\n",
    "\n",
    "max_diff = -1\n",
    "for l in range(1,len(old_weights)):\n",
    "\told_layer_weights = old_weights[l][0]\n",
    "\tnew_retrained_weights = retrained_weights[l][0]\n",
    "\n",
    "\tdifference = abs(old_layer_weights - new_retrained_weights)\n",
    "\t\n",
    "\tfor list_weights in difference:\n",
    "\t\tmax_distance = max(list_weights)\n",
    "\t\tif max_distance > max_diff:\n",
    "\t\t\tmax_diff = max_distance\n",
    "\n",
    "print(\"\\nThe maximum distance between weights is:\", max_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CFX computation: in the following cells we both compute the CFX using MILP and the proposed probabilistic APΔS approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:10,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total computation time in s: 10.735352039337158\n",
      "found: 1.0\n",
      "average normalised L1: 0.04218988369320217\n",
      "average normalised L0: 0.2116399999999999\n",
      "average lof score: 1.0\n",
      "counterfactual validity: 1.0\n",
      "delta validity: 0.0\n",
      "m2 validity: 1.0\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# OURS-ROBUST: compute CFX based on the n sound points discovered above\n",
    "ours_robust_ces_apas = util_exp.run_ours_robust(approx=True)\n",
    "util_exp.evaluate_ces(ours_robust_ces_apas)\n",
    "cfxs_robust_apas = ours_robust_ces_apas\n",
    "print(len(cfxs_robust_apas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:03, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total computation time in s: 3.5024325847625732\n",
      "found: 1.0\n",
      "average normalised L1: 0.05878411805181261\n",
      "average normalised L0: 0.23737999999999992\n",
      "average lof score: 1.0\n",
      "counterfactual validity: 1.0\n",
      "delta validity: 1.0\n",
      "m2 validity: 1.0\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# OURS-ROBUST: compute CFX based on the n sound points discovered above\n",
    "ours_robust_ces = util_exp.run_ours_robust()\n",
    "util_exp.evaluate_ces(ours_robust_ces)\n",
    "cfxs_robust = ours_robust_ces\n",
    "print(len(cfxs_robust))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing how many robust CFX remains robust after the retraining (i.e., expanding the $\\delta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage CFXs robust after the retraing: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# double checking the robustness of the CFXs found by APΔS approach after retraining\n",
    "tot_robust_cfx = len(cfxs_robust_apas)\n",
    "robust_cfx_after_retrain = 0\n",
    "\n",
    "for cfx in cfxs_robust_apas:\n",
    "    if model_retrained(np.array(cfx.reshape(1,-1))) >= 0.5:\n",
    "        robust_cfx_after_retrain += 1\n",
    "\n",
    "print(f\"Percentage CFXs robust after the retraing: {(robust_cfx_after_retrain/tot_robust_cfx)*100}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage CFXs robust after the retraing: 100.0%\n"
     ]
    }
   ],
   "source": [
    "tot_robust_cfx = len(cfxs_robust)\n",
    "robust_cfx_after_retrain = 0\n",
    "\n",
    "for cfx in cfxs_robust:\n",
    "    if model_retrained(np.array(cfx.reshape(1,-1))) >= 0.5:\n",
    "        robust_cfx_after_retrain += 1\n",
    "\n",
    "print(f\"Percentage CFXs robust after the retraing: {(robust_cfx_after_retrain/tot_robust_cfx)*100}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: probabilistic approximation approach to compute $\\Delta$-robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_robustness(model, delta, cfx, concretizations, use_biases=True, robustness=True):\n",
    "\n",
    "    \"\"\"\n",
    "    Utility method for the estimation of the CFX (not) Δ-robustness in the INN.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        rate: float\n",
    "            estimation of the CFX (not) Δ-robustness computed with 'concretizations' models concretizations from the INN\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    # Store initial weights\n",
    "    old_weights = {}\n",
    "    for l in range(1,len(model.layers)):\n",
    "        old_weights[l] = model.layers[l].get_weights()\n",
    "\n",
    "    for _ in range(concretizations):\n",
    "        \n",
    "        #perturbated_weights = {}\n",
    "        input_features = np.array(cfx)\n",
    "\n",
    "        for l in range(1,len(old_weights)+1):\n",
    "            layer_weights = old_weights[l][0]\n",
    "            if use_biases: layer_biases  = old_weights[l][1]\n",
    "            \n",
    "            weights_perturbation = np.random.uniform(-delta, delta, layer_weights.shape)\n",
    "            if use_biases: biases_perturbation = np.random.uniform(-delta, delta, layer_biases.shape)\n",
    "           \n",
    "            \n",
    "            layer_weights = [layer_weights+weights_perturbation]\n",
    "\n",
    "            if use_biases: \n",
    "                layer_biases = [layer_biases+biases_perturbation]\n",
    "                preactivated_res = np.dot(input_features, layer_weights) + layer_biases\n",
    "            else:\n",
    "                preactivated_res = np.dot(input_features, layer_weights)\n",
    "\n",
    "            if l != len(old_weights):\n",
    "                #relu\n",
    "                activated_res = np.maximum(0.0, preactivated_res)\n",
    "            else:\n",
    "                #sigmoid\n",
    "                activated_res = 1/(1 + np.exp(-preactivated_res))\n",
    "            \n",
    "            input_features = activated_res\n",
    "            \n",
    "        if input_features < 0.5:\n",
    "            return 0  \n",
    "    \n",
    "    return 1\n",
    "\n",
    "def compute_delta_max_MILP(cfx, delta_init, verbose=False):\n",
    "  \n",
    "    lower = 1/(1 + np.exp(-util_exp.is_robust_custom_delta_new(cfx, delta_init)))\n",
    "    if lower < 0.5: return 0 # CFX not robust\n",
    "        \n",
    "    delta = delta_init\n",
    "    while lower >= 0.5: # over-approx lower bound is >= 0.5, i.e., x results robust\n",
    "        delta = 2*delta\n",
    "        lower = 1/(1 + np.exp(-util_exp.is_robust_custom_delta_new(cfx, delta)))\n",
    "        if verbose: \n",
    "            print(f'Testing δ={delta}')\n",
    "            print(f'Lower is: {lower}')\n",
    "    \n",
    "    delta_max = delta/2\n",
    "    \n",
    "    while True:\n",
    "        if abs(delta-delta_max) < delta_init:\n",
    "            return delta_max\n",
    "\n",
    "        if verbose: print(f\"\\nInterval to test is: [{delta_max}, {delta}]\")\n",
    "        \n",
    "        delta_new = (delta_max+delta)/2\n",
    "        lower = 1/(1 + np.exp(-util_exp.is_robust_custom_delta_new(cfx, delta_new)))\n",
    "        if verbose: \n",
    "            print(f'Testing δ={delta_new}')\n",
    "            print(f'Rate is: {lower}')\n",
    "        \n",
    "        if lower >= 0.5:\n",
    "            delta_max = delta_new\n",
    "        else:\n",
    "            delta = delta_new\n",
    "\n",
    "\n",
    "\n",
    "def compute_delta_max(model, cfx, delta_init, concretizations, use_biases=True, verbose=False):\n",
    "  \n",
    "    rate = estimate_robustness(model, delta_init, cfx, concretizations, use_biases)\n",
    "    if rate != 1: return 0 # CFX not robust\n",
    "        \n",
    "    delta = delta_init\n",
    "    while rate == 1: # for all the concretizations x results robust\n",
    "        delta = 2*delta\n",
    "        rate = estimate_robustness(model, delta, cfx, concretizations, use_biases)\n",
    "        if verbose: \n",
    "            print(f'Testing δ={delta}')\n",
    "            print(f'Rate is: {rate}')\n",
    "    \n",
    "    delta_max = delta/2\n",
    "    \n",
    "    while True:\n",
    "        if abs(delta-delta_max) < delta_init:\n",
    "            return delta_max\n",
    "\n",
    "        if verbose: print(f\"\\nInterval to test is: [{delta_max}, {delta}]\")\n",
    "        \n",
    "        delta_new = (delta_max+delta)/2\n",
    "        rate = estimate_robustness(model, delta_new, cfx, concretizations, use_biases)\n",
    "        if verbose: \n",
    "            print(f'Testing δ={delta_new}')\n",
    "            print(f'Rate is: {rate}')\n",
    "        \n",
    "        if rate == 1:\n",
    "            delta_max = delta_new\n",
    "        else:\n",
    "            delta = delta_new\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mCondifence α =(1-R^n)=99.89995272421471%, R=99.5%, Concretizations(n)=1378\u001b[0m\n",
      "δ_max = 0.07800000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05560000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.082\n",
      "δ improvement w.r.t original MILP's δ is 0.0598\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08650000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.0627\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08195\n",
      "δ improvement w.r.t original MILP's δ is 0.05904999999999999\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07115000000000002\n",
      "δ improvement w.r.t original MILP's δ is 0.04955000000000002\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08715\n",
      "δ improvement w.r.t original MILP's δ is 0.06295\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07405\n",
      "δ improvement w.r.t original MILP's δ is 0.051250000000000004\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07800000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05560000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08100000000000002\n",
      "δ improvement w.r.t original MILP's δ is 0.058400000000000014\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.0685\n",
      "δ improvement w.r.t original MILP's δ is 0.0449\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.0745\n",
      "δ improvement w.r.t original MILP's δ is 0.05199999999999999\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.082\n",
      "δ improvement w.r.t original MILP's δ is 0.0598\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07950000000000002\n",
      "δ improvement w.r.t original MILP's δ is 0.05730000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.0719\n",
      "δ improvement w.r.t original MILP's δ is 0.0509\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08565\n",
      "δ improvement w.r.t original MILP's δ is 0.062450000000000006\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07\n",
      "δ improvement w.r.t original MILP's δ is 0.0476\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08715\n",
      "δ improvement w.r.t original MILP's δ is 0.06295\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08715\n",
      "δ improvement w.r.t original MILP's δ is 0.06295\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07475000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05285000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07195000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05005000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07700000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05390000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.0745\n",
      "δ improvement w.r.t original MILP's δ is 0.05199999999999999\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.06434999999999999\n",
      "δ improvement w.r.t original MILP's δ is 0.042849999999999985\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07800000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05560000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08005000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05835000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07800000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05560000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07205\n",
      "δ improvement w.r.t original MILP's δ is 0.050949999999999995\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08580000000000002\n",
      "δ improvement w.r.t original MILP's δ is 0.06100000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07\n",
      "δ improvement w.r.t original MILP's δ is 0.0476\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07205\n",
      "δ improvement w.r.t original MILP's δ is 0.050949999999999995\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07405\n",
      "δ improvement w.r.t original MILP's δ is 0.051250000000000004\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.0879\n",
      "δ improvement w.r.t original MILP's δ is 0.06390000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07820000000000002\n",
      "δ improvement w.r.t original MILP's δ is 0.055300000000000016\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07950000000000002\n",
      "δ improvement w.r.t original MILP's δ is 0.05730000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08565\n",
      "δ improvement w.r.t original MILP's δ is 0.062450000000000006\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.082\n",
      "δ improvement w.r.t original MILP's δ is 0.0598\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.06785\n",
      "δ improvement w.r.t original MILP's δ is 0.046049999999999994\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.06939999999999999\n",
      "δ improvement w.r.t original MILP's δ is 0.04619999999999999\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.0731\n",
      "δ improvement w.r.t original MILP's δ is 0.050949999999999995\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07\n",
      "δ improvement w.r.t original MILP's δ is 0.0476\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.06540000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.04320000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07195000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05005000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07850000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05590000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.06740000000000002\n",
      "δ improvement w.r.t original MILP's δ is 0.045300000000000014\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.0879\n",
      "δ improvement w.r.t original MILP's δ is 0.06390000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07800000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05560000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.08650000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.0627\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.06434999999999999\n",
      "δ improvement w.r.t original MILP's δ is 0.042849999999999985\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07700000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.05390000000000001\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.07205\n",
      "δ improvement w.r.t original MILP's δ is 0.050949999999999995\n",
      "______________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./models/no2.h5', compile=False)\n",
    "alpha = 0.999\n",
    "R = 0.995\n",
    "concretizations = int(np.emath.logn(R, (1-alpha)))\n",
    "delta_init = 0.0001\n",
    "delta_AAAI = 0.020924421229148754\n",
    "\n",
    "with open(\"full_results_no2.csv\", mode='w', newline='') as file:\n",
    "\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow([\"CFX\", \"AAAI δ_max\", \"Wilks δ_max\", \"MILP δ_max\", \"Difference\"])\n",
    "\n",
    "    wilks = []\n",
    "    milp = []\n",
    "    print( f\"{CYAN_COL}Condifence α =(1-R^n)={(1-R**concretizations)*100}%, R={R*100}%, Concretizations(n)={concretizations}{RESET_COL}\")\n",
    "\n",
    "    # start computing the new deltas with the approximation\n",
    "    for cfx in cfxs_robust:\n",
    "\n",
    "        delta_max_sampling = compute_delta_max(model, cfx.reshape(1,-1), delta_init, concretizations,verbose=False)\n",
    "        delta_max_MILP = compute_delta_max_MILP(cfx, delta_init,verbose=False) \n",
    "        difference = abs(delta_max_sampling-delta_max_MILP)\n",
    "        wilks.append(delta_max_sampling)\n",
    "        milp.append(delta_max_MILP)\n",
    "        csv_writer.writerow([cfx,  delta_AAAI, delta_max_sampling, delta_max_MILP, difference])\n",
    "\n",
    "        print('δ_max =', delta_max_sampling)\n",
    "        print('δ improvement w.r.t original MILP\\'s δ is',difference)\n",
    "        print(\"______________________________________________________________________________________\")\n",
    "\n",
    "\n",
    "\n",
    "    csv_writer.writerow([\" \"])\n",
    "    csv_writer.writerow([\"Mean MILP\",\"Mean Wilks\"])\n",
    "    csv_writer.writerow([np.mean(np.array(milp)),np.mean(np.array(wilks))])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
