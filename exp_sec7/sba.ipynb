{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiments ECAI24 on the small business administration dataset\n",
    "\n",
    "temporal shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# sci-kit learn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from util_scripts.convert import extract_sklearn_params, custom_nn_model\n",
    "from joblib import dump, load\n",
    "import gurobipy\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 150\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from util_scripts.preprocessor import Preprocessor, min_max_scale\n",
    "from util_scripts.utilexp import *\n",
    "from interval import *\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "CYAN_COL = '\\033[96m'\n",
    "BLUE_COL = '\\033[94m'\n",
    "RED_COL = '\\033[91m'\n",
    "GREEN_COL = '\\033[92m'\n",
    "YELLOW_COL = '\\033[93m'\n",
    "RESET_COL = '\\033[0m'\n",
    "BOLD = '\\033[1m'\n",
    "UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/sba/SBAcase.11.13.17.csv\", delimiter=',')\n",
    "df = df.dropna(axis=1)\n",
    "df = df.drop(columns=['ApprovalDate', \"LoanNr_ChkDgt\", \"Name\", \"Zip\", \"City\", \"State\", \"NAICS\", \"FranchiseCode\", 'BalanceGross', \"MIS_Status\", \"Selected\", \"UrbanRural\", 'Recession', 'New', 'RealEstate', 'Portion'])\n",
    "continuous_features = ['Term', 'NoEmp', 'CreateJob', 'RetainedJob',\n",
    "       'DisbursementGross', 'ChgOffPrinGr', 'GrAppv', 'SBA_Appv',\n",
    "       'daysterm']\n",
    "\n",
    "df1 = df[df['ApprovalFY'] < 2006].drop(columns=\"ApprovalFY\")\n",
    "df2 = df[df['ApprovalFY'] >= 2006].drop(columns=\"ApprovalFY\")\n",
    "df = df.drop(columns=[\"ApprovalFY\"])\n",
    "# min max scale\n",
    "min_vals = np.min(df[continuous_features], axis=0)\n",
    "max_vals = np.max(df[continuous_features], axis=0)\n",
    "df1_mm = min_max_scale(df1, continuous_features, min_vals, max_vals)\n",
    "df2_mm = min_max_scale(df2, continuous_features, min_vals, max_vals)\n",
    "\n",
    "# get X, y\n",
    "X1, y1 = df1_mm.drop(columns=['Default']), pd.DataFrame(1 - df1_mm['Default'])\n",
    "X2, y2 = df2_mm.drop(columns=['Default']), pd.DataFrame(1 - df2_mm['Default'])\n",
    "SPLIT = .2\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, stratify=y1, test_size=SPLIT, shuffle=True,\n",
    "                                                    random_state=5)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, stratify=y2, test_size=SPLIT, shuffle=True,\n",
    "                                                    random_state=2)\n",
    "\n",
    "ordinal_features = {}\n",
    "discrete_features = {}\n",
    "columns = list(df1_mm.columns)\n",
    "feat_var_map = {}\n",
    "for i in range(len(X1.columns)):\n",
    "    feat_var_map[i] = [i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>ChgOffPrinGr</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>daysterm</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.009231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083351</td>\n",
       "      <td>0.069933</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040290</td>\n",
       "      <td>0.036422</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>0.017868</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211256</td>\n",
       "      <td>0.176429</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1159 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Term     NoEmp  CreateJob  RetainedJob  DisbursementGross  \\\n",
       "0     0.117647  0.001538        0.0          0.0           0.012110   \n",
       "1     0.183007  0.001538        0.0          0.0           0.010893   \n",
       "2     0.117647  0.015385        0.0          0.0           0.010893   \n",
       "3     0.117647  0.009231        0.0          0.0           0.019551   \n",
       "5     0.274510  0.001538        0.0          0.0           0.022072   \n",
       "...        ...       ...        ...          ...                ...   \n",
       "2089  0.980392  0.001538        0.0          0.0           0.084481   \n",
       "2098  0.980392  0.006154        0.0          0.0           0.040761   \n",
       "2099  0.274510  0.003077        0.0          0.0           0.019551   \n",
       "2100  0.392157  0.004615        0.0          0.0           0.106622   \n",
       "2101  0.196078  0.006154        0.0          0.0           0.013058   \n",
       "\n",
       "      ChgOffPrinGr    GrAppv  SBA_Appv  daysterm  Default  \n",
       "0              0.0  0.010872  0.006035  0.117647        0  \n",
       "1              0.0  0.010872  0.006035  0.183007        0  \n",
       "2              0.0  0.010872  0.006035  0.117647        0  \n",
       "3              0.0  0.019399  0.010768  0.117647        0  \n",
       "5              0.0  0.019399  0.010768  0.274510        0  \n",
       "...            ...       ...       ...       ...      ...  \n",
       "2089           0.0  0.083351  0.069933  0.980392        0  \n",
       "2098           0.0  0.040290  0.036422  0.980392        0  \n",
       "2099           0.0  0.019399  0.017868  0.274510        0  \n",
       "2100           0.0  0.211256  0.176429  0.392157        0  \n",
       "2101           0.0  0.013004  0.007218  0.196078        0  \n",
       "\n",
       "[1159 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df1_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>ChgOffPrinGr</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>daysterm</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>0.121495</td>\n",
       "      <td>0.146381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144319</td>\n",
       "      <td>0.161283</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.879085</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.126686</td>\n",
       "      <td>0.163674</td>\n",
       "      <td>0.124920</td>\n",
       "      <td>0.104544</td>\n",
       "      <td>0.879085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.026930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.248366</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.248366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.037383</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008740</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.043690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040716</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.037948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.009231</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.011215</td>\n",
       "      <td>0.310006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305479</td>\n",
       "      <td>0.340196</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.043077</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.052336</td>\n",
       "      <td>0.443330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436794</td>\n",
       "      <td>0.485978</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.062838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062034</td>\n",
       "      <td>0.034434</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Term     NoEmp  CreateJob  RetainedJob  DisbursementGross  \\\n",
       "4     0.784314  0.100000   0.023077     0.121495           0.146381   \n",
       "6     0.879085  0.003077   0.000000     0.003738           0.126686   \n",
       "7     0.274510  0.001538   0.015385     0.001869           0.026930   \n",
       "13    0.248366  0.003077   0.000000     0.003738           0.010893   \n",
       "15    0.196078  0.020000   0.053846     0.037383           0.008729   \n",
       "...        ...       ...        ...          ...                ...   \n",
       "2093  0.274510  0.004615   0.000000     0.005607           0.043690   \n",
       "2094  0.274510  0.004615   0.000000     0.005607           0.037948   \n",
       "2095  0.784314  0.009231   0.030769     0.011215           0.310006   \n",
       "2096  0.784314  0.043077   0.061538     0.052336           0.443330   \n",
       "2097  0.196078  0.007692   0.000000     0.009346           0.062838   \n",
       "\n",
       "      ChgOffPrinGr    GrAppv  SBA_Appv  daysterm  Default  \n",
       "4         0.000000  0.144319  0.161283  0.784314        0  \n",
       "6         0.163674  0.124920  0.104544  0.879085        1  \n",
       "7         0.000000  0.010872  0.006035  0.274510        0  \n",
       "13        0.019675  0.010872  0.006035  0.248366        1  \n",
       "15        0.000000  0.008740  0.004851  0.196078        0  \n",
       "...            ...       ...       ...       ...      ...  \n",
       "2093      0.000000  0.040716  0.022601  0.274510        0  \n",
       "2094      0.000000  0.010872  0.006035  0.274510        0  \n",
       "2095      0.000000  0.305479  0.340196  0.784314        0  \n",
       "2096      0.000000  0.436794  0.485978  0.784314        0  \n",
       "2097      0.000000  0.062034  0.034434  0.196078        0  \n",
       "\n",
       "[943 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train and observe model changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 5, 'learning_rate_init': 0.02, 'hidden_layer_sizes': 12, 'batch_size': 8}\n"
     ]
    }
   ],
   "source": [
    "# Randomdised search + 5-fold cross validation (default)\n",
    "nn = MLPClassifier(learning_rate='adaptive', random_state=0)\n",
    "\n",
    "# parameters\n",
    "max_iter_vals = [2, 3, 4, 5]\n",
    "hidden_layer_sizes_vals = [(i) for i in range(3, 20)]\n",
    "batch_size_vals = [8, 16, 32, 64]\n",
    "learning_rate_init_vals = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05]\n",
    "\n",
    "#distributions = dict(max_iter=max_iter_vals, hidden_layer_sizes=hidden_layer_sizes_vals)\n",
    "distributions = dict(hidden_layer_sizes=hidden_layer_sizes_vals,\n",
    "                     batch_size=batch_size_vals,\n",
    "                     learning_rate_init=learning_rate_init_vals,\n",
    "                     max_iter=max_iter_vals)\n",
    "\n",
    "nns = RandomizedSearchCV(nn, distributions, scoring='f1_macro')\n",
    "#nns = RandomizedSearchCV(nn, distributions, scoring='accuracy')\n",
    "search = nns.fit(X1, y1)\n",
    "print(search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94 test_accuracy with a std of 0.01\n",
      "0.92 test_precision_macro with a std of 0.04\n",
      "0.87 test_recall_macro with a std of 0.03\n",
      "0.89 test_f1_macro with a std of 0.02\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " bad credit (0)      1.000     0.946     0.972        37\n",
      "good credit (1)      0.990     1.000     0.995       195\n",
      "\n",
      "       accuracy                          0.991       232\n",
      "      macro avg      0.995     0.973     0.984       232\n",
      "   weighted avg      0.991     0.991     0.991       232\n",
      "\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " bad credit (0)      0.965     0.926     0.945       149\n",
      "good credit (1)      0.986     0.994     0.990       778\n",
      "\n",
      "       accuracy                          0.983       927\n",
      "      macro avg      0.976     0.960     0.967       927\n",
      "   weighted avg      0.983     0.983     0.983       927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(learning_rate='adaptive', hidden_layer_sizes=6, learning_rate_init=0.05, batch_size=8,\n",
    "                    max_iter=5, random_state=0)\n",
    "# 5-fold cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "scores = cross_validate(clf, X1, y1, scoring=scoring)\n",
    "for name in list(scores.keys()):\n",
    "    if name == 'fit_time' or name == 'score_time':\n",
    "        continue\n",
    "    print(\"%0.2f %s with a std of %0.2f\" % (scores[name].mean(), name, scores[name].std()))\n",
    "\n",
    "#clf = MLPClassifier(learning_rate='adaptive', hidden_layer_sizes=18, learning_rate_init=0.005, batch_size=8,\n",
    "#                    max_iter=9000, random_state=0)\n",
    "clf = MLPClassifier(learning_rate='adaptive', hidden_layer_sizes=18, learning_rate_init=0.005, batch_size=8,\n",
    "                    max_iter=9000, random_state=0)\n",
    "clf.fit(X1_train, y1_train)\n",
    "resres = clf.predict(X1_test.values)\n",
    "print('\\n', classification_report(y1_test, resres, target_names=[f'bad credit (0)', f'good credit (1)'], digits=3))\n",
    "resres = clf.predict(X1_train.values)\n",
    "print('\\n', classification_report(y1_train, resres, target_names=[f'bad credit (0)', f'good credit (1)'], digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sba.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the trained classifier\n",
    "dump(clf, 'sba.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiments: computing counterfactuals\n",
    "\n",
    "#### Procedures\n",
    "\n",
    "These procedures are covered by UtilExp class\n",
    "\n",
    "1. Train M on D1\n",
    "2. Get delta-min, build M+ and M-: incrementally train M 5 times, using different 10% of D2 each time, then get the maximum inf-distance between the incremented models and M. Construct M+ and M- using delta-min\n",
    "3. Get M2: incrementally train M on D2\n",
    "4. Select test instances: randomly select 50 D1 instances to explain, clf(x)=0, desired class=1\n",
    "5. Report metrics using each baseline\n",
    "\n",
    "#### Metrics\n",
    "- Proximity: normalised L1: \"Scaling Guarantees for Nearest CEs\" page 7\n",
    "- Sparsity: L0\n",
    "- Validity-delta: percentage of test instances that 1) have counterfactuals valid on m1, 2) counterfactuals valid on M+ and M- under delta_min\n",
    "- Validity-m2: percentage of test instances that 1) have counterfactual(s), 2) these counterfactual(s) are all valid on both m1 and m2\n",
    "- LOF: average LOF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Set parameter FeasibilityTol to value 0.001\n",
      "Set parameter OptimalityTol to value 0.001\n",
      "Set parameter IntFeasTol to value 0.001\n"
     ]
    }
   ],
   "source": [
    "clf = load(\"sba.joblib\")\n",
    "gurobipy.setParam(\"FeasibilityTol\", 1e-03)\n",
    "gurobipy.setParam(\"OptimalityTol\", 1e-03)\n",
    "gurobipy.setParam(\"IntFeasTol\", 1e-03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30498064647513345\n",
      "0.10821238236127151\n"
     ]
    }
   ],
   "source": [
    "util_exp = UtilExp(clf, X1, y1, X2, y2, columns, ordinal_features, discrete_features, continuous_features, feat_var_map, gap=0.25, num_test_instances=200)\n",
    "print(util_exp.delta_max)\n",
    "print(util_exp.delta_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model trained on the whole dataset\n",
    "m2 = copy.deepcopy(clf)\n",
    "m2.partial_fit(X2, y2)\n",
    "util_exp.Mmax = m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of sound model changes: 0.6348314606741573\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "# pre-verification on the points soundness \n",
    "valids = util_exp.verify_soundness()\n",
    "print(len(valids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of sound model changes: 0.6348314606741573\n",
      "test instances updated to sound (x, Delta) pairs, length: 50\n"
     ]
    }
   ],
   "source": [
    "valids = util_exp.verify_soundness(update_test_instances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The maximum distance between weights is: 0.24813461\n"
     ]
    }
   ],
   "source": [
    "input_size, n_layers, output_size, output_act, h_act, optimizer, params = extract_sklearn_params(clf)\n",
    "tf_model = custom_nn_model(input_size, n_layers, params, output_size, h_act, output_act, optimizer)\n",
    "     \n",
    "# Set model weights\n",
    "for k, v in params.items():\n",
    "\ttf_model.layers[k].set_weights(v)\n",
    "        \n",
    "tf_model.save('./models/sba.h5', save_format='h5')   \n",
    "\n",
    "input_size, n_layers, output_size, output_act, h_act, optimizer, params = extract_sklearn_params(m2)\n",
    "tf_model = custom_nn_model(input_size, n_layers, params, output_size, h_act, output_act, optimizer)\n",
    "     \n",
    "# Set model weights\n",
    "for k, v in params.items():\n",
    "\ttf_model.layers[k].set_weights(v)\n",
    "\t\n",
    "tf_model.save('./models/sba_retrained.h5', save_format='h5')  \n",
    "\n",
    "original_model = tf.keras.models.load_model('./models/sba.h5', compile=False)\n",
    "old_weights = {}\n",
    "for l in range(1,len(original_model.layers)):\n",
    "\told_weights[l] = original_model.layers[l].get_weights()\n",
    "\n",
    "\n",
    "model_retrained = tf.keras.models.load_model('./models/sba_retrained.h5', compile=False)\n",
    "retrained_weights = {}\n",
    "for l in range(1,len(model_retrained.layers)):\n",
    "\tretrained_weights[l] = model_retrained.layers[l].get_weights()\n",
    "\n",
    "\n",
    "max_diff = -1\n",
    "for l in range(1,len(old_weights)):\n",
    "\told_layer_weights = old_weights[l][0]\n",
    "\tnew_retrained_weights = retrained_weights[l][0]\n",
    "\n",
    "\tdifference = abs(old_layer_weights - new_retrained_weights)\n",
    "\t\n",
    "\tfor list_weights in difference:\n",
    "\t\tmax_distance = max(list_weights)\n",
    "\t\tif max_distance > max_diff:\n",
    "\t\t\tmax_diff = max_distance\n",
    "\n",
    "print(\"\\nThe maximum distance between weights is:\", max_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CFX computation: in the following cells we both compute the CFX using MILP and the proposed probabilistic APΔS approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:21,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total computation time in s: 21.692475080490112\n",
      "found: 1.0\n",
      "average normalised L1: 0.008920690895365926\n",
      "average normalised L0: 0.1642800000000001\n",
      "average lof score: 0.4\n",
      "counterfactual validity: 1.0\n",
      "delta validity: 0.0\n",
      "m2 validity: 1.0\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# OURS-ROBUST: compute CFX based on the n sound points discovered above\n",
    "ours_robust_ces_apas = util_exp.run_ours_robust(approx=True)\n",
    "util_exp.evaluate_ces(ours_robust_ces_apas)\n",
    "cfxs_robust_apas = ours_robust_ces_apas\n",
    "print(len(cfxs_robust_apas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:23,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total computation time in s: 23.9276442527771\n",
      "found: 1.0\n",
      "average normalised L1: 0.018392337205926063\n",
      "average normalised L0: 0.27084\n",
      "average lof score: -0.88\n",
      "counterfactual validity: 1.0\n",
      "delta validity: 1.0\n",
      "m2 validity: 1.0\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# OURS-ROBUST: compute CFX based on the n sound points discovered above\n",
    "ours_robust_ces = util_exp.run_ours_robust()\n",
    "util_exp.evaluate_ces(ours_robust_ces)\n",
    "cfxs_robust = ours_robust_ces\n",
    "print(len(cfxs_robust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage CFXs robust after the retraing: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# double checking the robustness of the CFXs found by APΔS approach after retraining\n",
    "tot_robust_cfx = len(cfxs_robust_apas)\n",
    "robust_cfx_after_retrain = 0\n",
    "\n",
    "for cfx in cfxs_robust_apas:\n",
    "    if model_retrained(np.array(cfx.reshape(1,-1))) >= 0.5:\n",
    "        robust_cfx_after_retrain += 1\n",
    "\n",
    "print(f\"Percentage CFXs robust after the retraing: {(robust_cfx_after_retrain/tot_robust_cfx)*100}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage CFXs robust after the retraing: 100.0%\n"
     ]
    }
   ],
   "source": [
    "tot_robust_cfx = len(cfxs_robust)\n",
    "robust_cfx_after_retrain = 0\n",
    "\n",
    "for cfx in cfxs_robust:\n",
    "    if model_retrained(np.array(cfx.reshape(1,-1))) >= 0.5:\n",
    "        robust_cfx_after_retrain += 1\n",
    "\n",
    "print(f\"Percentage CFXs robust after the retraing: {(robust_cfx_after_retrain/tot_robust_cfx)*100}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_robustness(model, delta, cfx, concretizations, use_biases=True, robustness=True):\n",
    "\n",
    "    \"\"\"\n",
    "    Utility method for the estimation of the CFX (not) Δ-robustness in the INN.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        rate: float\n",
    "            estimation of the CFX (not) Δ-robustness computed with 'concretizations' models concretizations from the INN\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    # Store initial weights\n",
    "    old_weights = {}\n",
    "    for l in range(1,len(model.layers)):\n",
    "        old_weights[l] = model.layers[l].get_weights()\n",
    "\n",
    "    for _ in range(concretizations):\n",
    "        \n",
    "        #perturbated_weights = {}\n",
    "        input_features = np.array(cfx)\n",
    "\n",
    "        for l in range(1,len(old_weights)+1):\n",
    "            layer_weights = old_weights[l][0]\n",
    "            if use_biases: layer_biases  = old_weights[l][1]\n",
    "            \n",
    "            weights_perturbation = np.random.uniform(-delta, delta, layer_weights.shape)\n",
    "            if use_biases: biases_perturbation = np.random.uniform(-delta, delta, layer_biases.shape)\n",
    "           \n",
    "            \n",
    "            layer_weights = [layer_weights+weights_perturbation]\n",
    "\n",
    "            if use_biases: \n",
    "                layer_biases = [layer_biases+biases_perturbation]\n",
    "                preactivated_res = np.dot(input_features, layer_weights) + layer_biases\n",
    "            else:\n",
    "                preactivated_res = np.dot(input_features, layer_weights)\n",
    "\n",
    "            if l != len(old_weights):\n",
    "                #relu\n",
    "                activated_res = np.maximum(0.0, preactivated_res)\n",
    "            else:\n",
    "                #sigmoid\n",
    "                activated_res = 1/(1 + np.exp(-preactivated_res))\n",
    "            \n",
    "            input_features = activated_res\n",
    "            \n",
    "        if input_features < 0.5:\n",
    "            return 0  \n",
    "    \n",
    "    return 1\n",
    "\n",
    "def compute_delta_max_MILP(cfx, delta_init, verbose=False):\n",
    "  \n",
    "    lower = 1/(1 + np.exp(-util_exp.is_robust_custom_delta_new(cfx, delta_init)))\n",
    "    if lower < 0.5: return 0 # CFX not robust\n",
    "        \n",
    "    delta = delta_init\n",
    "    while lower >= 0.5: # over-approx lower bound is >= 0.5, i.e., x results robust\n",
    "        delta = 2*delta\n",
    "        lower = 1/(1 + np.exp(-util_exp.is_robust_custom_delta_new(cfx, delta)))\n",
    "        if verbose: \n",
    "            print(f'Testing δ={delta}')\n",
    "            print(f'Lower is: {lower}')\n",
    "    \n",
    "    delta_max = delta/2\n",
    "    \n",
    "    while True:\n",
    "        if abs(delta-delta_max) < delta_init:\n",
    "            return delta_max\n",
    "\n",
    "        if verbose: print(f\"\\nInterval to test is: [{delta_max}, {delta}]\")\n",
    "        \n",
    "        delta_new = (delta_max+delta)/2\n",
    "        lower = 1/(1 + np.exp(-util_exp.is_robust_custom_delta_new(cfx, delta_new)))\n",
    "        if verbose: \n",
    "            print(f'Testing δ={delta_new}')\n",
    "            print(f'Rate is: {lower}')\n",
    "        \n",
    "        if lower >= 0.5:\n",
    "            delta_max = delta_new\n",
    "        else:\n",
    "            delta = delta_new\n",
    "\n",
    "\n",
    "\n",
    "def compute_delta_max(model, cfx, delta_init, concretizations, use_biases=True, verbose=False):\n",
    "  \n",
    "    rate = estimate_robustness(model, delta_init, cfx, concretizations, use_biases)\n",
    "    if rate != 1: return 0 # CFX not robust\n",
    "        \n",
    "    delta = delta_init\n",
    "    while rate == 1: # for all the concretizations x results robust\n",
    "        delta = 2*delta\n",
    "        rate = estimate_robustness(model, delta, cfx, concretizations, use_biases)\n",
    "        if verbose: \n",
    "            print(f'Testing δ={delta}')\n",
    "            print(f'Rate is: {rate}')\n",
    "    \n",
    "    delta_max = delta/2\n",
    "    \n",
    "    while True:\n",
    "        if abs(delta-delta_max) < delta_init:\n",
    "            return delta_max\n",
    "\n",
    "        if verbose: print(f\"\\nInterval to test is: [{delta_max}, {delta}]\")\n",
    "        \n",
    "        delta_new = (delta_max+delta)/2\n",
    "        rate = estimate_robustness(model, delta_new, cfx, concretizations, use_biases)\n",
    "        if verbose: \n",
    "            print(f'Testing δ={delta_new}')\n",
    "            print(f'Rate is: {rate}')\n",
    "        \n",
    "        if rate == 1:\n",
    "            delta_max = delta_new\n",
    "        else:\n",
    "            delta = delta_new\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mCondifence α =(1-R^n)=99.89995272421471%, R=99.5%, Concretizations(n)=1378\u001b[0m\n",
      "δ_max = 0.28790000000000004\n",
      "δ improvement w.r.t original MILP's δ is 0.17810000000000004\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.29594999999999994\n",
      "δ improvement w.r.t original MILP's δ is 0.18674999999999992\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3016\n",
      "δ improvement w.r.t original MILP's δ is 0.19229999999999997\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.29699999999999993\n",
      "δ improvement w.r.t original MILP's δ is 0.18749999999999994\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.28800000000000003\n",
      "δ improvement w.r.t original MILP's δ is 0.17790000000000003\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3068\n",
      "δ improvement w.r.t original MILP's δ is 0.19645\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.2701\n",
      "δ improvement w.r.t original MILP's δ is 0.16165\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.30820000000000003\n",
      "δ improvement w.r.t original MILP's δ is 0.19670000000000004\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3108\n",
      "δ improvement w.r.t original MILP's δ is 0.20085000000000003\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.28200000000000003\n",
      "δ improvement w.r.t original MILP's δ is 0.1738\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.31420000000000003\n",
      "δ improvement w.r.t original MILP's δ is 0.20335000000000003\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.45310000000000006\n",
      "δ improvement w.r.t original MILP's δ is 0.34475000000000006\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3811\n",
      "δ improvement w.r.t original MILP's δ is 0.2729\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.30000000000000004\n",
      "δ improvement w.r.t original MILP's δ is 0.18850000000000006\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.29679999999999995\n",
      "δ improvement w.r.t original MILP's δ is 0.18674999999999994\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.29069999999999996\n",
      "δ improvement w.r.t original MILP's δ is 0.18184999999999996\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3077000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.19935000000000008\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3016\n",
      "δ improvement w.r.t original MILP's δ is 0.19229999999999997\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.36434999999999995\n",
      "δ improvement w.r.t original MILP's δ is 0.25534999999999997\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3753000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.26700000000000007\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3077000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.19885000000000008\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3214\n",
      "δ improvement w.r.t original MILP's δ is 0.21130000000000002\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.30674999999999997\n",
      "δ improvement w.r.t original MILP's δ is 0.19694999999999996\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.28680000000000005\n",
      "δ improvement w.r.t original MILP's δ is 0.17750000000000005\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3077000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.19935000000000008\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.2948\n",
      "δ improvement w.r.t original MILP's δ is 0.1855\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.33410000000000006\n",
      "δ improvement w.r.t original MILP's δ is 0.22540000000000004\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.29490000000000005\n",
      "δ improvement w.r.t original MILP's δ is 0.18495000000000006\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3168000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.20690000000000008\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3659\n",
      "δ improvement w.r.t original MILP's δ is 0.2558\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.30910000000000004\n",
      "δ improvement w.r.t original MILP's δ is 0.19880000000000003\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3214\n",
      "δ improvement w.r.t original MILP's δ is 0.21130000000000002\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.31074999999999997\n",
      "δ improvement w.r.t original MILP's δ is 0.20044999999999996\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.30000000000000004\n",
      "δ improvement w.r.t original MILP's δ is 0.18970000000000004\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.2992\n",
      "δ improvement w.r.t original MILP's δ is 0.1905\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.28970000000000007\n",
      "δ improvement w.r.t original MILP's δ is 0.18005000000000007\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.2993\n",
      "δ improvement w.r.t original MILP's δ is 0.1895\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.2948\n",
      "δ improvement w.r.t original MILP's δ is 0.1855\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.29190000000000005\n",
      "δ improvement w.r.t original MILP's δ is 0.18160000000000004\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.29569999999999996\n",
      "δ improvement w.r.t original MILP's δ is 0.18669999999999995\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.30820000000000003\n",
      "δ improvement w.r.t original MILP's δ is 0.19670000000000004\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.4262\n",
      "δ improvement w.r.t original MILP's δ is 0.31625000000000003\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.2992\n",
      "δ improvement w.r.t original MILP's δ is 0.1905\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3106\n",
      "δ improvement w.r.t original MILP's δ is 0.20079999999999998\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3077000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.19885000000000008\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.29610000000000003\n",
      "δ improvement w.r.t original MILP's δ is 0.18555000000000002\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.2866000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.17490000000000006\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.4206\n",
      "δ improvement w.r.t original MILP's δ is 0.31094999999999995\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.3113\n",
      "δ improvement w.r.t original MILP's δ is 0.19995000000000002\n",
      "______________________________________________________________________________________\n",
      "δ_max = 0.4145000000000001\n",
      "δ improvement w.r.t original MILP's δ is 0.3047500000000001\n",
      "______________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./models/sba.h5', compile=False)\n",
    "alpha = 0.999\n",
    "R = 0.995\n",
    "concretizations = int(np.emath.logn(R, (1-alpha)))\n",
    "delta_init = 0.0001\n",
    "delta_AAAI = 0.10821238236127151\n",
    "\n",
    "with open(\"full_results_sba.csv\", mode='w', newline='') as file:\n",
    "\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow([\"CFX\", \"AAAI δ_max\", \"Wilks δ_max\", \"MILP δ_max\", \"Difference\"])\n",
    "\n",
    "    wilks = []\n",
    "    milp = []\n",
    "    print( f\"{CYAN_COL}Condifence α =(1-R^n)={(1-R**concretizations)*100}%, R={R*100}%, Concretizations(n)={concretizations}{RESET_COL}\")\n",
    "\n",
    "    # start computing the new deltas with the approximation\n",
    "    for cfx in cfxs_robust:\n",
    "\n",
    "        delta_max_sampling = compute_delta_max(model, cfx.reshape(1,-1), delta_init, concretizations,verbose=False)\n",
    "        delta_max_MILP = compute_delta_max_MILP(cfx, delta_init,verbose=False) \n",
    "        difference = abs(delta_max_sampling-delta_max_MILP)\n",
    "        wilks.append(delta_max_sampling)\n",
    "        milp.append(delta_max_MILP)\n",
    "        csv_writer.writerow([cfx,  delta_AAAI, delta_max_sampling, delta_max_MILP, difference])\n",
    "\n",
    "        print('δ_max =', delta_max_sampling)\n",
    "        print('δ improvement w.r.t original MILP\\'s δ is',difference)\n",
    "        print(\"______________________________________________________________________________________\")\n",
    "\n",
    "\n",
    "\n",
    "    csv_writer.writerow([\" \"])\n",
    "    csv_writer.writerow([\"Mean Wilks\", \"Mean MILP\"])\n",
    "    csv_writer.writerow([np.mean(np.array(milp)),np.mean(np.array(wilks))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
